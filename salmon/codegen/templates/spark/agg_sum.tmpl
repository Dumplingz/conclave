
# assume rows of hdfs file are indexed by col id's
k_id = int({{{KEYCOL_ID}}})
a_id = int({{{AGGCOL_ID}}})

# get relevant cols by id
cols = {{{INREL}}} \
    .filter(lambda x: x[1] == k_id) or x[1] == a_id) \
    .map(lambda x: x[0])

# separate rdd into target cols
keyCol = cols \
    .filter(lambda x: x[1] = k_id) \
    .map(lambda x: x[0])

aggCol = cols \
    .filter(lambda x: x[1] = a_id) \
    .map(lambda x: x[0])

data = keyCol.zip(aggCol)

{{{OUTREL}}} = data.aggregateByKey([0], \
    lambda acc, val: list(numpy.add(acc,val)), \
    lambda acc1, acc2: list(numpy.add(acc1, acc2)))

# these should correspond to selectedCols in a Project node
{{{OUTREL}}}_{{{KEYCOL_ID}}} = {{{OUTREL}}}.keys()
{{{OUTREL}}}_{{{AGGCOL_ID}}} = {{{OUTREL}}}.values()
